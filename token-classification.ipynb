{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Preparing the data","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nraw_datasets=load_dataset(\"conll2003\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:24:59.003534Z","iopub.execute_input":"2025-07-13T07:24:59.003793Z","iopub.status.idle":"2025-07-13T07:25:10.286462Z","shell.execute_reply.started":"2025-07-13T07:24:59.003764Z","shell.execute_reply":"2025-07-13T07:25:10.285794Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2152d7edfdee4029add7471ef1a8ee79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0e6aa9f97c14379ab115e231656cf52"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e65c47fc8484de8a0f8515402845f1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"961a4c62cefb494493a0aa5b8a6c3f39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55d61c5177804a97bd28fac2ae675e5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92a7b247f00149d7bff1719b950676c9"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"raw_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:10.287101Z","iopub.execute_input":"2025-07-13T07:25:10.287314Z","iopub.status.idle":"2025-07-13T07:25:10.292305Z","shell.execute_reply.started":"2025-07-13T07:25:10.287297Z","shell.execute_reply":"2025-07-13T07:25:10.291559Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"raw_datasets[\"train\"][0][\"tokens\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:10.293756Z","iopub.execute_input":"2025-07-13T07:25:10.293956Z","iopub.status.idle":"2025-07-13T07:25:10.316880Z","shell.execute_reply.started":"2025-07-13T07:25:10.293939Z","shell.execute_reply":"2025-07-13T07:25:10.316150Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"raw_datasets[\"train\"][0][\"ner_tags\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:10.317602Z","iopub.execute_input":"2025-07-13T07:25:10.317805Z","iopub.status.idle":"2025-07-13T07:25:10.335768Z","shell.execute_reply.started":"2025-07-13T07:25:10.317787Z","shell.execute_reply":"2025-07-13T07:25:10.335029Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[3, 0, 7, 0, 0, 0, 7, 0, 0]"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"ner_features=raw_datasets[\"train\"].features[\"ner_tags\"]\nner_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:10.336665Z","iopub.execute_input":"2025-07-13T07:25:10.336986Z","iopub.status.idle":"2025-07-13T07:25:10.353339Z","shell.execute_reply.started":"2025-07-13T07:25:10.336959Z","shell.execute_reply":"2025-07-13T07:25:10.352757Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"label_names=ner_features.feature.names\nlabel_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:10.354140Z","iopub.execute_input":"2025-07-13T07:25:10.354430Z","iopub.status.idle":"2025-07-13T07:25:10.369916Z","shell.execute_reply.started":"2025-07-13T07:25:10.354405Z","shell.execute_reply":"2025-07-13T07:25:10.369365Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"words = raw_datasets[\"train\"][0][\"tokens\"]\nlabels = raw_datasets[\"train\"][0][\"ner_tags\"]\nline1 = \"\"\nline2 = \"\"\nfor word, label in zip(words, labels):\n    full_label = label_names[label]\n    max_length = max(len(word), len(full_label))\n    line1 += word + \" \" * (max_length - len(word) + 1)\n    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n\nprint(line1)\nprint(line2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:10.370764Z","iopub.execute_input":"2025-07-13T07:25:10.371017Z","iopub.status.idle":"2025-07-13T07:25:10.386151Z","shell.execute_reply.started":"2025-07-13T07:25:10.370991Z","shell.execute_reply":"2025-07-13T07:25:10.385410Z"}},"outputs":[{"name":"stdout","text":"EU    rejects German call to boycott British lamb . \nB-ORG O       B-MISC O    O  O       B-MISC  O    O \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\n\nwords = raw_datasets[\"train\"][0][\"tokens\"]\npos_labels = raw_datasets[\"train\"][0][\"pos_tags\"]  # use \"chunk_tags\" if needed\n\n# Map IDs to label names\npos_label_names = raw_datasets[\"train\"].features[\"pos_tags\"].feature.names\n\nline1 = \"\"\nline2 = \"\"\nfor word, label in zip(words, pos_labels):\n    full_label = pos_label_names[label]\n    max_length = max(len(word), len(full_label))\n    line1 += word + \" \" * (max_length - len(word) + 1)\n    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n\nprint(line1)\nprint(line2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:10.387216Z","iopub.execute_input":"2025-07-13T07:25:10.387585Z","iopub.status.idle":"2025-07-13T07:25:10.405193Z","shell.execute_reply.started":"2025-07-13T07:25:10.387564Z","shell.execute_reply":"2025-07-13T07:25:10.404444Z"}},"outputs":[{"name":"stdout","text":"EU  rejects German call to boycott British lamb . \nNNP VBZ     JJ     NN   TO VB      JJ      NN   . \n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"chunk_labels = raw_datasets[\"train\"][0][\"chunk_tags\"]\nchunk_label_names = raw_datasets[\"train\"].features[\"chunk_tags\"].feature.names\n\n\nline1 = \"\"\nline2 = \"\"\nfor word, label in zip(words, pos_labels):\n    full_label = pos_label_names[label]\n    max_length = max(len(word), len(full_label))\n    line1 += word + \" \" * (max_length - len(word) + 1)\n    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n\nprint(line1)\nprint(line2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:10.407723Z","iopub.execute_input":"2025-07-13T07:25:10.408299Z","iopub.status.idle":"2025-07-13T07:25:10.422180Z","shell.execute_reply.started":"2025-07-13T07:25:10.408278Z","shell.execute_reply":"2025-07-13T07:25:10.421555Z"}},"outputs":[{"name":"stdout","text":"EU  rejects German call to boycott British lamb . \nNNP VBZ     JJ     NN   TO VB      JJ      NN   . \n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Processing the data[","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"bert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:10.422822Z","iopub.execute_input":"2025-07-13T07:25:10.423003Z","iopub.status.idle":"2025-07-13T07:25:19.614520Z","shell.execute_reply.started":"2025-07-13T07:25:10.422988Z","shell.execute_reply":"2025-07-13T07:25:19.613880Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25c406dc63d04247a92eb52bc9d8a0a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"081240fd4a304c159093534e7a4b29c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35c2f945e51b449691fc1203a0b476b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31398ce44c0449739bb92017429f5fb6"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"inputs=tokenizer(raw_datasets[\"train\"][0][\"tokens\"],is_split_into_words=True)\ninputs.tokens()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:19.615196Z","iopub.execute_input":"2025-07-13T07:25:19.615597Z","iopub.status.idle":"2025-07-13T07:25:19.626373Z","shell.execute_reply.started":"2025-07-13T07:25:19.615578Z","shell.execute_reply":"2025-07-13T07:25:19.625747Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n 'EU',\n 'rejects',\n 'German',\n 'call',\n 'to',\n 'boycott',\n 'British',\n 'la',\n '##mb',\n '.',\n '[SEP]']"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"As we can see, the tokenizer added the special tokens used by the model ([CLS] at the beginning and [SEP] at the end) and left most of the words untouched. The word lamb, however, was tokenized into two subwords, la and ##mb. This introduces a mismatch between our inputs and the labels: the list of labels has only 9 elements, whereas our input now has 12 tokens. Accounting for the special tokens is easy (we know they are at the beginning and the end), but we also need to make sure we align all the labels with the proper words.","metadata":{}},{"cell_type":"code","source":"inputs.word_ids()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:19.627026Z","iopub.execute_input":"2025-07-13T07:25:19.627243Z","iopub.status.idle":"2025-07-13T07:25:19.641555Z","shell.execute_reply.started":"2025-07-13T07:25:19.627225Z","shell.execute_reply":"2025-07-13T07:25:19.640938Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def align_labels_with_tokens(labels, word_ids):\n    new_labels = []\n    current_word = None\n    for word_id in word_ids:\n        if word_id != current_word:\n            # Start of a new word!\n            current_word = word_id\n            label = -100 if word_id is None else labels[word_id]\n            new_labels.append(label)\n        elif word_id is None:\n            # Special token\n            new_labels.append(-100)\n        else:\n            # Same word as previous token\n            label = labels[word_id]\n            # If the label is B-XXX we change it to I-XXX\n            if label % 2 == 1:\n                label += 1\n            new_labels.append(label)\n\n    return new_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:19.642172Z","iopub.execute_input":"2025-07-13T07:25:19.642443Z","iopub.status.idle":"2025-07-13T07:25:19.658810Z","shell.execute_reply.started":"2025-07-13T07:25:19.642420Z","shell.execute_reply":"2025-07-13T07:25:19.658126Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"labels = raw_datasets[\"train\"][0][\"ner_tags\"]\nword_ids = inputs.word_ids()\nprint(labels)\nprint(align_labels_with_tokens(labels, word_ids))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:19.659549Z","iopub.execute_input":"2025-07-13T07:25:19.659747Z","iopub.status.idle":"2025-07-13T07:25:19.678476Z","shell.execute_reply.started":"2025-07-13T07:25:19.659732Z","shell.execute_reply":"2025-07-13T07:25:19.677611Z"}},"outputs":[{"name":"stdout","text":"[3, 0, 7, 0, 0, 0, 7, 0, 0]\n[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"], truncation=True, is_split_into_words=True\n    )\n    all_labels = examples[\"ner_tags\"]\n    new_labels = []\n    for i, labels in enumerate(all_labels):\n        word_ids = tokenized_inputs.word_ids(i)\n        new_labels.append(align_labels_with_tokens(labels, word_ids))\n\n    tokenized_inputs[\"labels\"] = new_labels\n    return tokenized_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:19.679185Z","iopub.execute_input":"2025-07-13T07:25:19.679440Z","iopub.status.idle":"2025-07-13T07:25:19.693039Z","shell.execute_reply.started":"2025-07-13T07:25:19.679411Z","shell.execute_reply":"2025-07-13T07:25:19.692352Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(\n    tokenize_and_align_labels,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:19.693723Z","iopub.execute_input":"2025-07-13T07:25:19.693929Z","iopub.status.idle":"2025-07-13T07:25:21.914671Z","shell.execute_reply.started":"2025-07-13T07:25:19.693913Z","shell.execute_reply":"2025-07-13T07:25:21.914087Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc78616c572c47c898600d5b150e0501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20dda3149afc4a0991dd27f9c369a8d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b75cae3ef5b4d7d9176431893fadf96"}},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"Fine-tuning the model with the Trainer API","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\ndata_collator=DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:21.915323Z","iopub.execute_input":"2025-07-13T07:25:21.915539Z","iopub.status.idle":"2025-07-13T07:25:35.048379Z","shell.execute_reply.started":"2025-07-13T07:25:21.915514Z","shell.execute_reply":"2025-07-13T07:25:35.047767Z"}},"outputs":[{"name":"stderr","text":"2025-07-13 07:25:23.559458: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752391523.768340      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752391523.829284      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\nbatch[\"labels\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:35.049199Z","iopub.execute_input":"2025-07-13T07:25:35.049788Z","iopub.status.idle":"2025-07-13T07:25:35.094996Z","shell.execute_reply.started":"2025-07-13T07:25:35.049762Z","shell.execute_reply":"2025-07-13T07:25:35.094162Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"for i in range(2):\n    print(tokenized_datasets[\"train\"][i][\"labels\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:35.095901Z","iopub.execute_input":"2025-07-13T07:25:35.096450Z","iopub.status.idle":"2025-07-13T07:25:35.126743Z","shell.execute_reply.started":"2025-07-13T07:25:35.096420Z","shell.execute_reply":"2025-07-13T07:25:35.126056Z"}},"outputs":[{"name":"stdout","text":"[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n[-100, 1, 2, -100]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n    collate_fn=data_collator,\n    shuffle=True,\n    batch_size=16,\n)\n\ntf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n    collate_fn=data_collator,\n    shuffle=False,\n    batch_size=16,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:25:35.127642Z","iopub.execute_input":"2025-07-13T07:25:35.127907Z","iopub.status.idle":"2025-07-13T07:25:35.921859Z","shell.execute_reply.started":"2025-07-13T07:25:35.127878Z","shell.execute_reply":"2025-07-13T07:25:35.921260Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1752391535.544562      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1752391535.545289      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"id2label = {i: label for i, label in enumerate(label_names)}\nlabel2id = {v: k for k, v in id2label.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:27:04.017251Z","iopub.execute_input":"2025-07-13T07:27:04.017576Z","iopub.status.idle":"2025-07-13T07:27:04.022068Z","shell.execute_reply.started":"2025-07-13T07:27:04.017549Z","shell.execute_reply":"2025-07-13T07:27:04.021064Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from transformers import TFAutoModelForTokenClassification\n\nmodel = TFAutoModelForTokenClassification.from_pretrained(\n    model_checkpoint,\n    id2label=id2label,\n    label2id=label2id,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:27:04.895957Z","iopub.execute_input":"2025-07-13T07:27:04.896255Z","iopub.status.idle":"2025-07-13T07:27:10.599236Z","shell.execute_reply.started":"2025-07-13T07:27:04.896229Z","shell.execute_reply":"2025-07-13T07:27:10.598448Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e8fd9bc6d554eaba0a4240b6fa698d3"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForTokenClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"model.config.num_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:27:56.028183Z","iopub.execute_input":"2025-07-13T07:27:56.028529Z","iopub.status.idle":"2025-07-13T07:27:56.034110Z","shell.execute_reply.started":"2025-07-13T07:27:56.028505Z","shell.execute_reply":"2025-07-13T07:27:56.033087Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"9"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"**Fine-tuning the model**","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:31:57.073524Z","iopub.execute_input":"2025-07-13T07:31:57.074131Z","iopub.status.idle":"2025-07-13T07:31:57.096738Z","shell.execute_reply.started":"2025-07-13T07:31:57.074106Z","shell.execute_reply":"2025-07-13T07:31:57.095703Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e2996420d2429eb23f426cbdd7c84e"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"!git config --global user.email \"aabdallahelmahdy@gmail.com\"\n!git config --global user.name \"Abdallah Elmahdy\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:44:13.086515Z","iopub.execute_input":"2025-07-13T07:44:13.087120Z","iopub.status.idle":"2025-07-13T07:44:13.424402Z","shell.execute_reply.started":"2025-07-13T07:44:13.087100Z","shell.execute_reply":"2025-07-13T07:44:13.423266Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from transformers import create_optimizer\nimport tensorflow as tf\n\n# Train in mixed-precision float16\n# Comment this line out if you're using a GPU that will not benefit from this\ntf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n\n# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\nnum_epochs = 3\nnum_train_steps = len(tf_train_dataset) * num_epochs\n\noptimizer, schedule = create_optimizer(\n    init_lr=2e-5,\n    num_warmup_steps=0,\n    num_train_steps=num_train_steps,\n    weight_decay_rate=0.01,\n)\nmodel.compile(optimizer=optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:44:18.488441Z","iopub.execute_input":"2025-07-13T07:44:18.489232Z","iopub.status.idle":"2025-07-13T07:44:18.506945Z","shell.execute_reply.started":"2025-07-13T07:44:18.489204Z","shell.execute_reply":"2025-07-13T07:44:18.506289Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from transformers.keras_callbacks import PushToHubCallback\n\ncallback = PushToHubCallback(output_dir=\"bert-finetuned-ner\", tokenizer=tokenizer)\n\nmodel.fit(\n    tf_train_dataset,\n    validation_data=tf_eval_dataset,\n    callbacks=[callback],\n    epochs=num_epochs,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:44:20.434131Z","iopub.execute_input":"2025-07-13T07:44:20.434999Z","iopub.status.idle":"2025-07-13T07:55:38.539970Z","shell.execute_reply.started":"2025-07-13T07:44:20.434962Z","shell.execute_reply":"2025-07-13T07:55:38.539326Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\n/kaggle/working/bert-finetuned-ner is already a clone of https://huggingface.co/aabdallahelmahdy/bert-finetuned-ner. Make sure you pull the latest changes with `repo.git_pull()`.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n878/878 [==============================] - 241s 248ms/step - loss: 0.0354 - val_loss: 0.0573\nEpoch 2/3\n878/878 [==============================] - 212s 242ms/step - loss: 0.0185 - val_loss: 0.0566\nEpoch 3/3\n878/878 [==============================] - 212s 241ms/step - loss: 0.0108 - val_loss: 0.0562\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7ba0bf2d4750>"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"*Metrics*","metadata":{}},{"cell_type":"code","source":"!pip install seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:56:03.829731Z","iopub.execute_input":"2025-07-13T07:56:03.830000Z","iopub.status.idle":"2025-07-13T07:56:10.254682Z","shell.execute_reply.started":"2025-07-13T07:56:03.829979Z","shell.execute_reply":"2025-07-13T07:56:10.253701Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=3631b0354b3843335c92de30c00c94788404fab1886100984a9d4c9f81942c4a\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:57:02.111299Z","iopub.execute_input":"2025-07-13T07:57:02.111876Z","iopub.status.idle":"2025-07-13T07:57:06.083680Z","shell.execute_reply.started":"2025-07-13T07:57:02.111850Z","shell.execute_reply":"2025-07-13T07:57:06.082914Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"seqeval\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:59:16.090489Z","iopub.execute_input":"2025-07-13T07:59:16.091316Z","iopub.status.idle":"2025-07-13T07:59:21.209010Z","shell.execute_reply.started":"2025-07-13T07:59:16.091282Z","shell.execute_reply":"2025-07-13T07:59:21.208513Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1804a4300ad347549cc228f4d42cba41"}},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"labels = raw_datasets[\"train\"][0][\"ner_tags\"]\nlabels = [label_names[i] for i in labels]\nlabels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:59:26.143071Z","iopub.execute_input":"2025-07-13T07:59:26.143816Z","iopub.status.idle":"2025-07-13T07:59:26.152280Z","shell.execute_reply.started":"2025-07-13T07:59:26.143789Z","shell.execute_reply":"2025-07-13T07:59:26.151554Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"predictions = labels.copy()\npredictions[2] = \"O\"\nmetric.compute(predictions=[predictions], references=[labels])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:59:28.816544Z","iopub.execute_input":"2025-07-13T07:59:28.816817Z","iopub.status.idle":"2025-07-13T07:59:28.831214Z","shell.execute_reply.started":"2025-07-13T07:59:28.816796Z","shell.execute_reply":"2025-07-13T07:59:28.830605Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'MISC': {'precision': 1.0,\n  'recall': 0.5,\n  'f1': 0.6666666666666666,\n  'number': 2},\n 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'overall_precision': 1.0,\n 'overall_recall': 0.6666666666666666,\n 'overall_f1': 0.8,\n 'overall_accuracy': 0.8888888888888888}"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_preds):\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": all_metrics[\"overall_precision\"],\n        \"recall\": all_metrics[\"overall_recall\"],\n        \"f1\": all_metrics[\"overall_f1\"],\n        \"accuracy\": all_metrics[\"overall_accuracy\"],\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:59:32.324435Z","iopub.execute_input":"2025-07-13T07:59:32.324711Z","iopub.status.idle":"2025-07-13T07:59:32.330196Z","shell.execute_reply.started":"2025-07-13T07:59:32.324692Z","shell.execute_reply":"2025-07-13T07:59:32.329522Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import numpy as np\n\nall_predictions = []\nall_labels = []\nfor batch in tf_eval_dataset:\n    logits = model.predict_on_batch(batch)[\"logits\"]\n    labels = batch[\"labels\"]\n    predictions = np.argmax(logits, axis=-1)\n    for prediction, label in zip(predictions, labels):\n        for predicted_idx, label_idx in zip(prediction, label):\n            if label_idx == -100:\n                continue\n            all_predictions.append(label_names[predicted_idx])\n            all_labels.append(label_names[label_idx])\nmetric.compute(predictions=[all_predictions], references=[all_labels])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T07:59:34.509148Z","iopub.execute_input":"2025-07-13T07:59:34.509437Z","iopub.status.idle":"2025-07-13T08:01:38.871768Z","shell.execute_reply.started":"2025-07-13T07:59:34.509413Z","shell.execute_reply":"2025-07-13T08:01:38.871170Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'LOC': {'precision': 0.9555436529191216,\n  'recall': 0.9711486118671747,\n  'f1': 0.9632829373650108,\n  'number': 1837},\n 'MISC': {'precision': 0.8548057259713702,\n  'recall': 0.9067245119305857,\n  'f1': 0.8799999999999999,\n  'number': 922},\n 'ORG': {'precision': 0.9078171091445427,\n  'recall': 0.9179716629381058,\n  'f1': 0.9128661475713754,\n  'number': 1341},\n 'PER': {'precision': 0.967741935483871,\n  'recall': 0.9771986970684039,\n  'f1': 0.9724473257698542,\n  'number': 1842},\n 'overall_precision': 0.9323543969641973,\n 'overall_recall': 0.9510265903736116,\n 'overall_f1': 0.9415979338498709,\n 'overall_accuracy': 0.9870636368988049}"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nraw_datasets=load_dataset(\"squad\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:12:34.337377Z","iopub.execute_input":"2025-07-15T05:12:34.337623Z","iopub.status.idle":"2025-07-15T05:12:38.568859Z","shell.execute_reply.started":"2025-07-15T05:12:34.337606Z","shell.execute_reply":"2025-07-15T05:12:38.568162Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dcd9b9092254c6e88b55c276f92e102"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88a6114294cb4e58bf7ad41c1b4d31c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/1.82M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11cf5556229b40b1a5e330beb41f7e6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211c0b6d9b9c4a30a1f9f69eb333a0f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9611be5f08b149449b319dd9b2fc7138"}},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"**preparing the data**","metadata":{}},{"cell_type":"code","source":"raw_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:12:38.570119Z","iopub.execute_input":"2025-07-15T05:12:38.570525Z","iopub.status.idle":"2025-07-15T05:12:38.575449Z","shell.execute_reply.started":"2025-07-15T05:12:38.570506Z","shell.execute_reply":"2025-07-15T05:12:38.574582Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 87599\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 10570\n    })\n})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"print(\"Context: \", raw_datasets[\"train\"][0][\"context\"])\nprint(\"Question: \", raw_datasets[\"train\"][0][\"question\"])\nprint(\"Answer: \", raw_datasets[\"train\"][0][\"answers\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:12:38.576434Z","iopub.execute_input":"2025-07-15T05:12:38.576771Z","iopub.status.idle":"2025-07-15T05:12:38.594455Z","shell.execute_reply.started":"2025-07-15T05:12:38.576750Z","shell.execute_reply":"2025-07-15T05:12:38.593778Z"}},"outputs":[{"name":"stdout","text":"Context:  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\nQuestion:  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\nAnswer:  {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"raw_datasets[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:12:38.596150Z","iopub.execute_input":"2025-07-15T05:12:38.596854Z","iopub.status.idle":"2025-07-15T05:12:39.956611Z","shell.execute_reply.started":"2025-07-15T05:12:38.596831Z","shell.execute_reply":"2025-07-15T05:12:39.955944Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df1fd25f75b04f3987545a09858a6a10"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'title', 'context', 'question', 'answers'],\n    num_rows: 0\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"**Processing the training data**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer \n\nmodel_checkpoint = \"bert-base-cased\"\ntokenizer=AutoTokenizer.from_pretrained(model_checkpoint)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:12:39.957442Z","iopub.execute_input":"2025-07-15T05:12:39.957737Z","iopub.status.idle":"2025-07-15T05:12:47.862799Z","shell.execute_reply.started":"2025-07-15T05:12:39.957716Z","shell.execute_reply":"2025-07-15T05:12:47.861798Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e4c4662be4a4439a16fba23eb976abf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca97276269704621ba9eb9bfabc89389"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3894ae51c8694d52bd314b63c0d66336"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6f0fa588be147daa27231fc1cd8f6ba"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"context=raw_datasets[\"train\"][0][\"context\"]\nquestion=raw_datasets[\"train\"][0][\"question\"]\ninputs=tokenizer(question,context)\ntokenizer.decode(inputs[\"input_ids\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:12:47.863773Z","iopub.execute_input":"2025-07-15T05:12:47.864249Z","iopub.status.idle":"2025-07-15T05:12:47.876397Z","shell.execute_reply.started":"2025-07-15T05:12:47.864225Z","shell.execute_reply":"2025-07-15T05:12:47.875982Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building \\' s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"inputs=tokenizer(\n    question,\n    context,\n    max_length=100,\n    truncation=\"only_second\",\n    stride=50,\n    return_overflowing_tokens=True\n)\nfor ids in inputs[\"input_ids\"]:\n    print(tokenizer.decode(ids))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:12:47.876868Z","iopub.execute_input":"2025-07-15T05:12:47.877136Z","iopub.status.idle":"2025-07-15T05:12:47.891656Z","shell.execute_reply.started":"2025-07-15T05:12:47.877117Z","shell.execute_reply":"2025-07-15T05:12:47.890975Z"}},"outputs":[{"name":"stdout","text":"[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building ' s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]\n[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]\n[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]\n[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"inputs = tokenizer(\n    question,\n    context,\n    max_length=100,\n    truncation=\"only_second\",\n    stride=50,\n    return_overflowing_tokens=True,\n    return_offsets_mapping=True,\n)\ninputs.keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:12:47.892511Z","iopub.execute_input":"2025-07-15T05:12:47.892752Z","iopub.status.idle":"2025-07-15T05:12:47.902767Z","shell.execute_reply.started":"2025-07-15T05:12:47.892730Z","shell.execute_reply":"2025-07-15T05:12:47.902325Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"inputs[\"overflow_to_sample_mapping\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:12:47.903597Z","iopub.execute_input":"2025-07-15T05:12:47.904027Z","iopub.status.idle":"2025-07-15T05:12:47.914288Z","shell.execute_reply.started":"2025-07-15T05:12:47.904005Z","shell.execute_reply":"2025-07-15T05:12:47.913550Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[0, 0, 0, 0]"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"inputs = tokenizer(\n    raw_datasets[\"train\"][2:6][\"question\"],\n    raw_datasets[\"train\"][2:6][\"context\"],\n    max_length=100,\n    truncation=\"only_second\",\n    stride=50,\n    return_overflowing_tokens=True,\n    return_offsets_mapping=True,\n)\n\nprint(f\"The 4 examples gave {len(inputs['input_ids'])} features.\")\nprint(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:12:47.916270Z","iopub.execute_input":"2025-07-15T05:12:47.916789Z","iopub.status.idle":"2025-07-15T05:12:47.931033Z","shell.execute_reply.started":"2025-07-15T05:12:47.916763Z","shell.execute_reply":"2025-07-15T05:12:47.930234Z"}},"outputs":[{"name":"stdout","text":"The 4 examples gave 19 features.\nHere is where each comes from: [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3].\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"answers = raw_datasets[\"train\"][2:6][\"answers\"]\nstart_positions = []\nend_positions = []\n\nfor i, offset in enumerate(inputs[\"offset_mapping\"]):\n    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n    answer = answers[sample_idx]\n    start_char = answer[\"answer_start\"][0]\n    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n    sequence_ids = inputs.sequence_ids(i)\n\n    # Find the start and end of the context\n    idx = 0\n    while sequence_ids[idx] != 1:\n        idx += 1\n    context_start = idx\n    while sequence_ids[idx] == 1:\n        idx += 1\n    context_end = idx - 1\n\n    # If the answer is not fully inside the context, label is (0, 0)\n    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n        start_positions.append(0)\n        end_positions.append(0)\n    else:\n        # Otherwise it's the start and end token positions\n        idx = context_start\n        while idx <= context_end and offset[idx][0] <= start_char:\n            idx += 1\n        start_positions.append(idx - 1)\n\n        idx = context_end\n        while idx >= context_start and offset[idx][1] >= end_char:\n            idx -= 1\n        end_positions.append(idx + 1)\n\nstart_positions, end_positions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:42:53.439804Z","iopub.execute_input":"2025-07-15T05:42:53.440548Z","iopub.status.idle":"2025-07-15T05:42:53.449757Z","shell.execute_reply.started":"2025-07-15T05:42:53.440524Z","shell.execute_reply":"2025-07-15T05:42:53.449108Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"([83, 51, 19, 0, 0, 64, 27, 0, 34, 0, 0, 0, 67, 34, 0, 0, 0, 0, 0],\n [85, 53, 21, 0, 0, 70, 33, 0, 40, 0, 0, 0, 68, 35, 0, 0, 0, 0, 0])"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"idx = 0\nsample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\nanswer = answers[sample_idx][\"text\"][0]\n\nstart = start_positions[idx]\nend = end_positions[idx]\nlabeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n\nprint(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:44:20.474900Z","iopub.execute_input":"2025-07-15T05:44:20.475200Z","iopub.status.idle":"2025-07-15T05:44:20.480302Z","shell.execute_reply.started":"2025-07-15T05:44:20.475180Z","shell.execute_reply":"2025-07-15T05:44:20.479627Z"}},"outputs":[{"name":"stdout","text":"Theoretical answer: the Main Building, labels give: the Main Building\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"max_length = 384\nstride = 128\n\n\ndef preprocess_training_examples(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        sample_idx = sample_map[i]\n        answer = answers[sample_idx]\n        start_char = answer[\"answer_start\"][0]\n        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find the start and end of the context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label is (0, 0)\n        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:45:54.398239Z","iopub.execute_input":"2025-07-15T05:45:54.398532Z","iopub.status.idle":"2025-07-15T05:45:54.406122Z","shell.execute_reply.started":"2025-07-15T05:45:54.398511Z","shell.execute_reply":"2025-07-15T05:45:54.405335Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_dataset = raw_datasets[\"train\"].map(\n    preprocess_training_examples,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names,\n)\nlen(raw_datasets[\"train\"]), len(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:46:19.212771Z","iopub.execute_input":"2025-07-15T05:46:19.213085Z","iopub.status.idle":"2025-07-15T05:47:01.961760Z","shell.execute_reply.started":"2025-07-15T05:46:19.213064Z","shell.execute_reply":"2025-07-15T05:47:01.961226Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7874245ccc1547ef97f686eceeacf613"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(87599, 88729)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def preprocess_validation_examples(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    example_ids = []\n\n    for i in range(len(inputs[\"input_ids\"])):\n        sample_idx = sample_map[i]\n        example_ids.append(examples[\"id\"][sample_idx])\n\n        sequence_ids = inputs.sequence_ids(i)\n        offset = inputs[\"offset_mapping\"][i]\n        inputs[\"offset_mapping\"][i] = [\n            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n        ]\n\n    inputs[\"example_id\"] = example_ids\n    return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:48:24.478678Z","iopub.execute_input":"2025-07-15T05:48:24.478988Z","iopub.status.idle":"2025-07-15T05:48:24.485074Z","shell.execute_reply.started":"2025-07-15T05:48:24.478965Z","shell.execute_reply":"2025-07-15T05:48:24.484240Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"validation_dataset = raw_datasets[\"validation\"].map(\n    preprocess_validation_examples,\n    batched=True,\n    remove_columns=raw_datasets[\"validation\"].column_names,\n)\nlen(raw_datasets[\"validation\"]), len(validation_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:48:33.244460Z","iopub.execute_input":"2025-07-15T05:48:33.245104Z","iopub.status.idle":"2025-07-15T05:48:40.486813Z","shell.execute_reply.started":"2025-07-15T05:48:33.245064Z","shell.execute_reply":"2025-07-15T05:48:40.486064Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb8b49fae58844a08d7d4e7a2a43dabf"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(10570, 10822)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"small_eval_set = raw_datasets[\"validation\"].select(range(100))\ntrained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n\ntokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\neval_set = small_eval_set.map(\n    preprocess_validation_examples,\n    batched=True,\n    remove_columns=raw_datasets[\"validation\"].column_names,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:58:30.348510Z","iopub.execute_input":"2025-07-15T05:58:30.348772Z","iopub.status.idle":"2025-07-15T05:58:31.246409Z","shell.execute_reply.started":"2025-07-15T05:58:30.348754Z","shell.execute_reply":"2025-07-15T05:58:31.245628Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bc9570fa7bb4d95873378f540f86760"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ac12f68d09448acaa53dc45dd0dd222"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b43ce84362444822bba56fde344fca27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d73036c90fb4dab8eb387bb16df8488"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d123f8f638b49788a35f7062874a392"}},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:58:43.914437Z","iopub.execute_input":"2025-07-15T05:58:43.914700Z","iopub.status.idle":"2025-07-15T05:58:44.115734Z","shell.execute_reply.started":"2025-07-15T05:58:43.914680Z","shell.execute_reply":"2025-07-15T05:58:44.114986Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering\n\neval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\neval_set_for_model.set_format(\"torch\")\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nbatch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\ntrained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(\n    device\n)\n\nwith torch.no_grad():\n    outputs = trained_model(**batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:58:47.844979Z","iopub.execute_input":"2025-07-15T05:58:47.845751Z","iopub.status.idle":"2025-07-15T05:58:50.876475Z","shell.execute_reply.started":"2025-07-15T05:58:47.845718Z","shell.execute_reply":"2025-07-15T05:58:50.875785Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efc4a8e93dd549a3a38d8a2720f77a22"}},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"start_logits = outputs.start_logits.cpu().numpy()\nend_logits = outputs.end_logits.cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:58:59.481898Z","iopub.execute_input":"2025-07-15T05:58:59.482611Z","iopub.status.idle":"2025-07-15T05:58:59.486829Z","shell.execute_reply.started":"2025-07-15T05:58:59.482580Z","shell.execute_reply":"2025-07-15T05:58:59.486233Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import collections\n\nexample_to_features = collections.defaultdict(list)\nfor idx, feature in enumerate(eval_set):\n    example_to_features[feature[\"example_id\"]].append(idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:59:13.059613Z","iopub.execute_input":"2025-07-15T05:59:13.060395Z","iopub.status.idle":"2025-07-15T05:59:13.152517Z","shell.execute_reply.started":"2025-07-15T05:59:13.060361Z","shell.execute_reply":"2025-07-15T05:59:13.151817Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import numpy as np\n\nn_best = 20\nmax_answer_length = 30\npredicted_answers = []\n\nfor example in small_eval_set:\n    example_id = example[\"id\"]\n    context = example[\"context\"]\n    answers = []\n\n    for feature_index in example_to_features[example_id]:\n        start_logit = start_logits[feature_index]\n        end_logit = end_logits[feature_index]\n        offsets = eval_set[\"offset_mapping\"][feature_index]\n\n        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n        for start_index in start_indexes:\n            for end_index in end_indexes:\n                # Skip answers that are not fully in the context\n                if offsets[start_index] is None or offsets[end_index] is None:\n                    continue\n                # Skip answers with a length that is either < 0 or > max_answer_length.\n                if (\n                    end_index < start_index\n                    or end_index - start_index + 1 > max_answer_length\n                ):\n                    continue\n\n                answers.append(\n                    {\n                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n                    }\n                )\n\n    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:59:22.336953Z","iopub.execute_input":"2025-07-15T05:59:22.337217Z","iopub.status.idle":"2025-07-15T05:59:29.009304Z","shell.execute_reply.started":"2025-07-15T05:59:22.337198Z","shell.execute_reply":"2025-07-15T05:59:29.008492Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"! pip install evaluate\nimport evaluate\n\nmetric = evaluate.load(\"squad\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T05:59:50.014063Z","iopub.execute_input":"2025-07-15T05:59:50.014824Z","iopub.status.idle":"2025-07-15T05:59:55.825073Z","shell.execute_reply.started":"2025-07-15T05:59:50.014793Z","shell.execute_reply":"2025-07-15T05:59:55.824285Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89571ca9f50f4b9dacdcfdec97a1279a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21e729e970ff4d2582211023a55ac312"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"theoretical_answers = [\n    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in small_eval_set\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:00:08.234820Z","iopub.execute_input":"2025-07-15T06:00:08.235607Z","iopub.status.idle":"2025-07-15T06:00:08.248215Z","shell.execute_reply.started":"2025-07-15T06:00:08.235574Z","shell.execute_reply":"2025-07-15T06:00:08.247461Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"print(predicted_answers[0])\nprint(theoretical_answers[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:00:13.969259Z","iopub.execute_input":"2025-07-15T06:00:13.969518Z","iopub.status.idle":"2025-07-15T06:00:13.973889Z","shell.execute_reply.started":"2025-07-15T06:00:13.969498Z","shell.execute_reply":"2025-07-15T06:00:13.973206Z"}},"outputs":[{"name":"stdout","text":"{'id': '56be4db0acb8001400a502ec', 'prediction_text': 'Denver Broncos'}\n{'id': '56be4db0acb8001400a502ec', 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}}\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"metric.compute(predictions=predicted_answers, references=theoretical_answers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T06:00:23.120992Z","iopub.execute_input":"2025-07-15T06:00:23.121245Z","iopub.status.idle":"2025-07-15T06:00:23.148657Z","shell.execute_reply.started":"2025-07-15T06:00:23.121228Z","shell.execute_reply":"2025-07-15T06:00:23.148125Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"{'exact_match': 83.0, 'f1': 88.25000000000004}"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}